# data-engineering-fullstack
This repository contains links to all resources for full stack data engineering skillset

## List of Target Companies

* [Razorpay] ()
* [Disruptors_Capital](http://www.disruptors.capital/) [Job_Description](https://www.linkedin.com/jobs/view/2850688238)
    * Very small company, recently started, less than 100 employees, investment company
    * Experience building scalable, real time and high-performance data lake solutions usingtech such **Kafka**, **AWS EMR, S3, Hive, Spark**- Experience with workflow scheduling tools like **Airflow**- Experience with relational and non-relational databases- Experience with scripting languages such as Shell, Python- Programming Languages: **Java / Python / Scala**- Experience working with micro service architecture- Experience working with cloud-based service providers (preferably AWS)- Knowledge of **linear and logistic regression, K-means, K-medoids, Naive Bayes, Decision tree, Random forest, Clustering, Bayesian model, CNN, Transformers** would be considered a plus- Knowledge of natural language processing (**NLP**) will be considered a plus
* [Walmart_Global_Tech_India](https://one.walmart.com/content/globaltechindia/en_in.html) [Job_Description](https://www.linkedin.com/jobs/view/2848676337) 
    * Bachelor's Degree or Master’s Degree with **3+ years** of experience in Computer Science or related field.
    * Experience in **ETL** and Expertise in **SQL**.
    * Expertise in Big Data Ecosystem with experience in **Hadoop, Hive, Spark, Strome, Cassandra, NoSQL DB’s**.
    * Expertise in **MPP architecture** and knowledge of MPP engine (Spark, **Impala** etc).
    * Data pipeline/workflow management tools such as **Azkaban, Airflow and oozie**
    * **Cloud** Development experience
    * Experience in building scalable/highly available distributed systems in production.
    * Understanding of **stream processing** with knowledge on **Kafka**.
    * Knowledge of Software Engineering best practices with experience on implementing CI/CD, Log aggregation/* * Monitoring/alerting for production system.
    * Very good expertise in production support related activities (issue identification, resolution)
* [Goldman_Sachs](http://www.goldmansachs.com/) [Job_Description_1](https://www.linkedin.com/jobs/view/2813599926) [Job_Description_2](https://www.linkedin.com/jobs/view/2814202082)
    * Advanced degree in Engineering, Computer Science or related disciplines
    * Hands-on experience with one or more mainstream programming languages (**Python, Java, C, Scala, C++**, etc.)
    * Hands-on experience with one or more relational database systems (**Sybase, Snowflake, Oracle**)
    * Experience in building data products from ideation to implementation
    * At least 2 years experience in a visualization tool such as **Tableau / QlikView / Spotfire / Power BI**
    * At least 3 years experience dealing with data (structured or unstructured)
    * Ability to use data for business analysis and to drive customer focussed ideas
    * Strong project management skills
    * Experience working in a start-up business or a new business line within a larger organization is preferred

* [Twilio](http://www.twilio.com/) [Job_Description](https://www.linkedin.com/jobs/view/2848216345) 
    * Product based (Chat App), IPO done, 11 rounds funding done
    * Minimum of 3+ years of technical experience supporting highly-available Data warehouse systems and ETLs.
    * Hands-on strong experience with **SQL/NoSQL** databases. A good understanding of troubleshooting highly **scalable Data warehouses and Data pipelines**.
    * Hands on Experience in **SQL , Python and Scala** programming languages.
    * Experience in supporting distributed environments using **Spark, Hive, Presto, Hadoop** etc.
    * Deep understanding of architecture and functioning of Distributed database systems like **Snowflake, Presto and Redshift** (any ) .
    * Experience working with various file formats like **Parquet, Avro, ORC** for large volumes of data
    * Experience with one or more NoSQL databases such as **Cassandra, MongoDB, DynamoDB** is a plus.
    * Strong understanding of engineering standard methodologies design principles
    * Experience working in agile environment and iterative development

* [Baker_Hughes](http://www.bakerhughes.com/) [Job_Description](https://www.linkedin.com/jobs/view/2849489228)
    * Baker Hughes (NASDAQ: BKR) is an energy technology company that provides solutions for energy and industrial customers worldwide.
    * Be a Graduate in Computer Engineering. A minimum 3 yrs of professional experience
    * Have minimum of 3 yrs of development in **Informatica or Talend**
    * Have minimum of 2 yrs of writing **advanced SQL and stored procedures**
    * Have Understanding of logical and physical **data models and data lineage**
    * Have good experience with SQL Database such as **Oracle MySQL, PostgreSQL**
    * Have hands-on experience with **star schema models** to convert and derive flat summary data models for analytics and summary statistics
    * Have experience with **cloud** technologies and open source tools like **python, spark, Java**
    * Have experience on new D&A application development and existing application optimization is required (data source identification, mapping, ingestion, modelling and transformation for analytical consumption purposes).

* [Hitachi_Vantara](Hitachi Vantara) [Job_Description](https://www.linkedin.com/jobs/view/2850487966)
    * wholly-owned subsidiary of Hitachi, Ltd., guides our customers from what’s now to what’s next by solving their digital challenges, More than 80% of the Fortune 100 trust Hitachi Vantara to help them develop new revenue stream
    * 5+ years' experience working in data & analytics ecosystem, working with structured, semi-structured and unstructured data.
    * Demonstrated experience with **Data Pipeline development** both on-premises and in the cloud (AWS/Azure) using open-source technology
    * Responsible for creating reusable and scalable data pipelines using **cloud ETL tools & technology like Azure Data Factory, Glue etc.**
    * Sound understanding of various data solution patterns and when to use them: **ETL/ELT, RDBMS, Normalization/De-normalization, Key-Value, In-Memory, Wide Column, Columnar, Text Indexing, Streaming, Messaging**
    * Strong software engineering and object-oriented programming skills with expertise in languages such as **SQL, Python.**
    * Strong **data warehousing, data modeling and data manipulation skills**, such as in SQL, Stored Procedures, SQL Server
    * Experience with Agile methodologies, such as Scrum, Kanban, Lean
    * Experience building data pipelines using **Databricks**.
    * Experience building on emerging cloud serverless managed services, to minimize/eliminate physical/virtual server footprint
    * Experience implementing security solutions for data storage and processing in the cloud

* [Zoom](https://www.zoom.us/) [Job_Description](https://www.linkedin.com/jobs/view/2848214174)
    * famous video call platform 
    * jd not given

* [Expedia_Group](http://www.lifeatexpediagroup.com/) [Job_Description](https://www.linkedin.com/jobs/view/2849027140)
    * travel company (product based)
    * this jd for 8 years experience

* [Trell](https://trell.co.in/) [Job_Description](https://www.linkedin.com/jobs/view/2848222710)
    * linkedin ranked top startup
    -Experience in building production big-data crunching systems (**Spark, Kafka, HIVE, Flink** etc)
    * Strong data architectural skills.
    * Strong problem-solving skills.
    * Knowledge of distributed computing using **Spark**.
    * Ability to work in cross-functional projects and drive decision making.
    * Ability to wrangle unstructured data, as per use cases.
    * Experience schema design, data modelling and manipulating large data sets using both relational (e.g., **MySQL Postgres**) and non-relational databases (e.g., **MongoDB, CouchDB, Redis, Cassandra**).
    * Ability to consume, transform and optimize complex SQL queries.
    * Solid knowledge in python and data structures & a software engineering mindset, striving to write elegant, maintainable code.
    * Reliable knowledge/experience in consuming Web Services.
    * Knowledge/experience in consuming **real-time data streams**.
    * Knowledge of data warehousing (**BigQuery, Redshift, Snowflake** etc.) and working with data lakes (**S3, ADLS**).
    * Knowledge of **statistical** and **machine learning** models and preprocessing techniques would be an added advantage

<h3> Domains for fullstack </h3>
<ul>
  <li> ETL </li>
  <li> Visualization </li>
  <li> Cloud </li>
</ul>

<h3> skills Required </h3>
<ul>
  <li> Airflow </li>
  <li> PowerBI </li>
  <li> Spark </li>
</ul>
